{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ActivePyTools.visualizing_tools import *\n",
    "from ActivePyTools.grab_data import eval_object_columns\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "crop_path = './docs/crop_pics/google/'\n",
    "pic_name = 'Bookshelves_5.jpg'\n",
    "temp_df = pd.read_csv('./data/Bookshelves_5_df.csv', encoding='utf-8')\n",
    "evaled_df = eval_object_columns(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaled_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84d8b98cd4509c36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def draw_text_on_image(text_row: pd.Series, image, padding: int = 10):\n",
    "    vertices = text_row.vertices\n",
    "    x_coords, y_coords = zip(*vertices)\n",
    "\n",
    "    min_x = max(int(min(x_coords) - padding), 0)\n",
    "    max_x = min(int(max(x_coords) + padding), image.shape[1])\n",
    "    min_y = max(int(min(y_coords) - padding), 0)\n",
    "    max_y = min(int(max(y_coords) + padding), image.shape[0])\n",
    "    # \n",
    "    # print(vertices)\n",
    "    # print(f\"{min_x}, {max_x}; {min_y}, {max_y}\")\n",
    "    # print(image.shape)\n",
    "\n",
    "    cropped_image = image[min_y:max_y, min_x:max_x]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(cropped_image, extent=[min_x, max_x, min_y, max_y])\n",
    "\n",
    "    ax.add_patch(draw_rectangle(get_text_data(text_row), color='red'))\n",
    "\n",
    "    ax.set_xlim(min_x, max_x)\n",
    "    ax.set_ylim(min_y, max_y)\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f290dcda2e79b816"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id = 144"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5031f4f13f4c8787"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id += 1\n",
    "print(id)\n",
    "text_row = evaled_df.iloc[id]\n",
    "print(text_row.txt)\n",
    "row, col = text_row.crop_idx\n",
    "img_path = crop_path + pic_name + '_' + str( row) + '_' + str(col) +'.jpg'\n",
    "\n",
    "draw_text_on_image(text_row, cv2.imread(img_path), padding=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7abc5da67ac8453"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check Similarity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b217bfa67e9f59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "difflib.SequenceMatcher(None, 'eautiful', 'beautiful').ratio()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd094ac6749f7537"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
